---
title: "MASCARA: coexpression analysis in data from designed experiments"
author: "Fred T.G. White, Anna Heintz-Buschart, Lemeng Dong, Harro J. Bouwmeester, Johan A. Westerhuis, Age K. Smilde"
date: '`r format(Sys.time(), "%d %B, %Y")`'
output: 
    bookdown::word_document2:
      number_sections: false
      toc: false
      classoption:
        twocolumn
bibliography: MASCARA_refs.json
csl: vancouver.csl
keep_md: true
link-citations: yes
header-includes:
  - \usepackage{multicol}
  - \usepackage{amsmath}
  - \usepackage{float}
  - \usepackage{bm}
  - \newcommand{\hideFromPandoc}[1]{#1}
  -  \hideFromPandoc{
       \let\Begin\begin
          \let\End\end
          }
          
---


```{r setup, include=FALSE}
library(knitr)
knitr::opts_chunk$set(echo = FALSE, warning = F, message = F, fig.pos = "H") #, root.dir=here()



# if(!"renv" %in% installed.packages()[,1]){
#   install.packages("renv")
# }
# 
# renv::restore(prompt = FALSE)
# renv::snapshot()

# renv::dependencies()
# renv::status()

#bibliography: "`r rbbt::bbt_write_bib('MASCARA_refs.json', overwrite = TRUE)`"

```



```{r , echo=FALSE, include=FALSE}
source("DATA_SIM_FUNCS.R")
source("MASCARA_FUNCS.R")
```




```{r, echo = FALSE, include=FALSE}
library(devtools)
library(ggplot2)
library(MetStaT)
library(gASCA)
library(patchwork)
library(readxl)
library(ggfortify)
library(ggrepel)
library(grid)
library(gridExtra)
library(tidyr)
library(tidyverse)
library(reshape2)
library(scales)
library(matrixStats)
library(DESeq2)
library(MASS)
library(glmnet)
library(doParallel)
library(MUVR)
library(pheatmap)
library(caret)
library(mixOmics)
library(cowplot)
library(reticulate)
library(biomformat)
library(DiscriMiner)
library(viridis)
library(directlabels)
library(ggpmisc)
library(DescTools)
library(data.table)
library(plotly)
library(ggbreak)
library(rhmmer)
library(pracma)
```



# Abstract

Experiments in plant transcriptomics are usually designed to induce variation in a pathway of interest. Harsh experimental conditions can cause widespread transcriptional changes between groups. Discovering coexpression within a pathway of interest (here the strigolactone pathway) in this context is hampered by the dominant variance induced by the design. Minor changes in experimental conditions not controlled for may affect the plants, leading to small coordinated differences in genes within pathways of interest and related pathways between replicate plants in the same controlled experimental condition. These systematic differences between replicates within the same experimental conditions can be used to detect genes from the same or related pathway. We introduce a novel framework “MASCARA” which combines ANOVA simultaneous component analysis and partial least squares to remove the experimentally induced variance and investigate multivariate relationships in the non-designed variance. MASCARA is tested against a selection of competitors on simulated data, created to mimic a designed transcriptome study. In a coexpression analysis of a real dataset MASCARA detects several uncharacterised but relevant transcripts. Our results indicate that there is sufficient structure left in a typical dataset after correcting for experimental variance and that this residual information is useful to investigate coexpression. 

<!-- \twocolumn -->

\Begin{multicols}{2}



# Introduction
Plant transcriptome studies typically involve the use of designed experiments which aim to induce variation in pathways of interest (POIs) by controlling one or more experimental factors. This can be done through, for example, varying the level of certain essential nutrients, knocking out/down a gene within a POI. To explore the effects of an intervention, gene expression can be measured through RNA sequencing (RNAseq). Analysis of RNAseq data generally adheres to one of two approaches: differential expression analysis (DE; @andersDifferentialExpressionAnalysis2010; @robinsonEdgeRBioconductorPackage2010) or coexpression analysis (CoE; @langfelderWGCNAPackageWeighted2008; @tzfadiaCoExpNetVizComparativeCoExpression2016). DE is used to determine which genes are expressed differently between two or more experimental conditions, highlighting known or novel pathways affected by the experimental conditions. CoE, on the other hand, aims at discovering genes that are part of an already partially characterized POI. Here, the expression profiles of known genes of the POI (termed "baits") are used to detect novel pathway members with similar expression patterns (here termed "targets"). 



```{r nettype, fig.cap= c("Pathway types exemplified, POI; pathway of interest, RP; related pathway, URP; unrelated pathway. Panel A represents hypothetical biological pathways  that are all affected by the experimental design and thus all contain DE genes, here the edges represent real connections between the nodes/genes. Panel B highlights the problem with detecting these pathways when dealing with data from designed experiments, here edges represent putative connections defined by coexpression analysis; black is desired (within network detection), grey non-desired.")}

a <- knitr::include_graphics("networktypes.png")
a
```


Figure \@ref(fig:nettype) outlines pathway nomenclature that will be used throughout this text. Panel *A* represents hypothetical pathways including a pathway of interest (POI), related pathway (RP) and an unrelated pathway (URP). All three types of pathway are assumed to be affected by the experimental design. URPs are defined to be pathways not directly interacting with the POI. In the hypothetical example displayed in Figure \@ref(fig:nettype), taking the purple triangles as baits, the desired outcome of a coexpression analysis would be to detect all other purple and orange coloured genes and not the light green genes. However, these connections are not always preferentially detected, this is due to the presence of different sources of variance in the data.

When dealing with experimentally designed data, we have to consider two key sources of variance: between-group and within-group. Between-group variance pertains to the differences between experimental groups (or conditions). This type of variance is of interest when conducting DE studies. Within-group variance, on the other hand, is the variance within experimental groups (among replicates), this is not interesting for DE studies but may contain information useful to CoE. It is the excessive between-group variance that leads to the densely connected nature of panel *B* from \@ref(fig:nettype). Concretising this with a biological example; in @haiderTranscriptomeAnalysisPhosphate2023 a phosphate (P) starvation was applied to rice plants to induce strigolactone (SL) biosynthesis, to study the change in gene expression in comparison to control plants with normal supplies of P. The SL pathway is known to be triggered through P deficiency. However, as P is one of three key nutrients for plant growth, deficiency of this nutrient causes widespread differential expression throughout the transcriptome (@wangRoleStrigolactonesDeficiency2021).

Figure \@ref(fig:withinbetween) exemplifies between-group and within-group driven correlations from a real dataset (@haiderTranscriptomeAnalysisPhosphate2023). The plots show the relationship between two genes of the POI (*A* and *C*) and the relationship between two genes that are not part of the same pathway (*B* and *D*). The total correlations in both *A* and *B* are high but correlation in *B* is driven by the between-group variation and not by correlations within experimental groups. The within-group correlation is lower than the total in both cases, but there is a clear trend in *C*: P- condition in red. The within group correlation (r) is higher for the first transcript pair (*C*) than the second (*D*), which makes it possible to discern between a POI gene or an URP gene. Hence, we need to distinguish *total CoE* which is calculated on the total variance and *within-group CoE* where the focus is on the shared variance within experimental groups. 

From a plant biology point of view, the between-group and the within-group variance can be quite different. However, both may contain valuable biological information. The between-group variance is in principle larger because groups are the result of treatments that are usually selected because they affect the POI. Within-group variance (variance across replicates), if too large, can be an issue in DE analysis, we argue that in co-expression analysis the information present in this variance can be valuable. Variance between replicates is caused by non-controlled variations in plant development and environmental conditions. One replicate plant within a group may be slightly bigger than the others and therefore respond slightly different to a treatment. This could result in slight differences in bait genes between the replicates, but also the genes that we want to identify with a co-expression analysis. There may be many other factors that are inducing this within-group variance, but it is quite likely that if a factor induces a change in the treatment response in one replicate, that this response difference occurs throughout the entire process or pathway in that one replicate. This means that the within-group variance likely contains valuable information and by averaging out this variance, as is done in differential expression analysis, we are losing information. Not making the distinction between types of variance results in *total CoE* associations driven by the differences between treatment groups as opposed to within group correlations. @haiderTranscriptomeAnalysisPhosphate2023 used ranked Pearson correlations to determine (total) coexpression candidates. Due to such a strong effect of the experiment, many genes were affected on top of the desired SL genes. This masked the within-group correlation between the baits and the targets (remaining unknown SL genes). This problematic issue was also highlighted recently by @saccentiWhatCanGo2023 where group sampling assumptions are investigated. Hence, both from a data analysis as well as from a biological perspective it is relevant to make a distinction between the different types of CoE. The focus of this paper will be on developing methods to investigate within-group CoE.


```{r withinbetween, fig.cap= c("Correlation examples, Pearson’s correlation coefficient (r) indicated in facet titles. Data from @haiderTranscriptomeAnalysisPhosphate2023. X axes, expression levels of MAX1 gene (Os01t0700900–01) in rice, Y axes expression levels of example coexpression candidates, aribitrary units. Top row A-B; *total CoE*, bottom row C-D *within-group CoE* from variance partitioning the data in A-B. Gene pairs in both A and B have strong total correlations. Correlation in A is also exhibited within a group, B has strong total correlations mainly due to the differences between groups. These examples are indistinguishable from eachother without variance partitioning.")}

a <- knitr::include_graphics("within_between_example_2.png")
a

```

For a successful coexpression analysis it is necessary to have a predefined set of baits that are already known to be involved in the pathway under study. Methods like ranked correlations and partial least squares regression (PLS; @geladiPartialLeastsquaresRegression1986; @woldCollinearityProblemLinear1984) are able to investigate relationships between a set of baits and the other measured genes. In ranked correlations the relationships are quantified at a bivariate level. In PLS regression the relationships can be investigated in a multivariate way, in its simplest form we can see which genes are most predictive of the expression of one bait. This can be extended to a PLS2 model where relationships are investigated between a set of multiple baits and all other genes. These methods do not by default account for the different variance types discussed above. Hence, they are not directly suitable for within-group CoE. 

The most widely known and applied method that investigates variance sources is the analysis of variance (ANOVA; @searleLinearModels1971). ANOVA simultaneous component analysis (ASCA; @smildeANOVAsimultaneousComponentAnalysis2005) and its extension to imbalanced data via the generalised linear model (ASCA+; @thielASCAAPCAExtensions2017) have been developed to combine principal component analysis (PCA) with ANOVA and can therefore account for experimental design in dimension reduction. ASCA is of interest due to the variance partitioning. This is typically used to estimate the effect matrices that are calculated from the design and particularly the within-group variance structure which is maintained in the residuals of the model. Both PLS and ASCA have been used for DE (@augerGeneCoexpressionNetwork2022, @renRNABindingProteins2023, @nuedaDiscoveringGeneExpression2007, @jarmundALASCAPackageLongitudinal2022) and CoE (@guanSRGSSparsePartial2022, @nuedaFunctionalAssessmentTime2009). ASCA and PLS have been combined before in @thissenImprovingAnalysisDesigned2009 creating ANOVA-PLS, however the goal of their study was not coexpression analysis. Neither of these methods are optimal by themselves for CoE in the context of large between group variance with known baits. 

The baits are assumed to be part of the same POI and the remaining uncharacterised targets (POI or RP genes) are assumed to be numerous. Therefore, both the baits and the remainder of the data could be reduced to linear combinations in order to investigate relationships between a set of baits and putative targets. We introduce a new data analysis method called multivariate ASCA residual analysis (MASCARA). MASCARA is motivated by four key factors; (1) the presence of dominant between-group variance caused by the setup of the experiment, as well as, (2) ambient variance (structured effects caused by undocumented environmental factors i.e. temperature, light intensity or soil water content) within the replicates of each experimental group, (3) the need to investigate multivariate relationships and (4) the low number of samples. The method capitalises on ASCA to account for an experimental design and the multivariate analysis capability of PLS2 to find uncharacterised POI genes using a set of baits. Instead of focusing on the variance induced by the experimental design, as is a typical use of ASCA, this variance is removed, and the remaining residual variance is further analysed to investigate the multivariate relationships between baits and the putative targets in terms of within-group CoE. 


To explore the utility of MASCARA, the method will be compared to ASCA, PLS2 and correlation analysis illustrated using an example RNAseq dataset (from @haiderTranscriptomeAnalysisPhosphate2023). Furthermore, this dataset is used as a guide to several simulation studies to validate the development of a novel approach to coexpression analysis. For these simulations we emulate both different levels of between- and within-group variance. We test the effects of size of between group differences, number of URP differential genes, measurement noise (random unstructured technical variance), structured ambient variance and number of replicates. The following sections seek to investigate which statistical methods are best suited for POI elucidation when a set of baits is already known and illustrate the benefit of MASCARA. Especially in data coming from experiments designed for differential expression analysis.




```{r, echo = FALSE, include=FALSE}
baits <- paste0("X_",c(1989:2000))   #501:510

meta <- cbind.data.frame(rep(c(1,-1), each = 12), rep(c(1:4), each = 3), rep(c(-1:-4,1:4), each = 3))
colnames(meta) <- c("growth_condition","time","interaction")
```
# Materials and Methods


```{r, echo = FALSE, include=FALSE}
META <- as.data.frame(meta[,1:2])
META$growth_condition[which(META$growth_condition == "1")] <- "P+"
META$growth_condition[which(META$growth_condition == "-1")] <- "P-"

```

```{r, echo = F}
META <- META[!duplicated(paste0(META$growth_condition, META$time)),]
rownames(META) <- NULL


fill <- rep(c("grey95", "grey90"), nrow(META))

theme1 <- gridExtra::ttheme_default(core = list(
  fg_params = list(fontface=c(rep("plain", nrow(META)))),
  bg_params = list(fill = fill)),
  base_size = 10, padding = unit(c(3, 3), "mm"))

META <- gridExtra::tableGrob(META, rows = NULL, theme = theme1)
title <- textGrob("Design",gp=gpar(fontsize=24))
META <- gtable::gtable_add_grob(META, title,1,1,1,ncol(META))

rdo <- readRDS("Data_Haider/RICE_DATA_OVERVIEW.RDS")
levels(rdo[[2]]$data$time) <- c("1","3","7","8")

```



## RNAseq - Rice strigolactone dataset @haiderTranscriptomeAnalysisPhosphate2023

In order to guide the simulations we illustrate the desired characteristics with a real dataset. The real data are a subset of samples from a study in which the root transcriptome of rice plants is measured under two  growth condition (P+/P-) and measured at four time points (1, 3, 7 and 8  days post treatment). At each combination of growth condition and time point, the root transcriptome of three new plants was harvested for RNA sequencing. In this dataset, the curated list of SL pathway genes (contained in Supplementary Table 1)  shows a specific profile: low variance baseline expression across all time points in the P+ condition but activation and increasing expression over time with P starvation, data were generated and preprocessed to variance stabilised counts as per @haiderTranscriptomeAnalysisPhosphate2023. 

Figure \@ref(fig:Dataset1-Overview) shows the gene expression levels of 9 strigolactone pathway genes along with 9 highly differential genes that are induced by P deficiency, but are not part of the SL pathway. While the expression is low in P+ condition a clear increasing time profile can be observed in the P- condition, indicating an interaction between the growth condition and the time factors.

What is notable here is the replicate specific patterns that are apparent amongst the SL genes and largely absent between the SLs (purple) and the non-SL differential genes (green). For example, at time point 3,  most SL genes are expressed lowest in replicate 1 and highest in replicate 3, while at time point 7 replicate 2 has a higher SL gene expression. These within-group patterns are either not shared at all between the SL genes and the other DE genes or to a much lesser extent. This is due to the other genes not directly being part of the same pathway. There are of course other pathways and thus there are still some subtle replicate patterns in the non-SL genes but this effect is much clearer within our pathway of interest. Figure \@ref(fig:ASCA-1) shows the output of the ASCA decomposition in which the PCA scores and loadings of the combined effect of the  Growth condition factor and the interaction of Growth condition and Time is explored. The score plot shows that the replicates of each condition are clustered while the difference between the conditions is much larger, as expected. While the 9 SL transcripts have higher loadings on the 1st PC, there are many non-SL transcripts with similarly (or more) extreme loadings. Thus many differentially expressed genes are found important that are not part of the SL pathway, in other words ASCA does not detect SL (POI) genes from others that are similarly or more differentially expressed but not part of the SL pathway (URPs).

This marks the goal of this paper, which is to detect within-group coexpressed genes (POI/RP) with a set of baits preferentially to other differentially expressed genes that are not part of the same pathway (URPs, with a different within-group structure).



\End{multicols}



```{r Dataset1-Overview, echo = F, fig.cap=c("Real data overview. RNAseq of rice root. Heatmap of SL pathway and example highly differential genes. Data and preprocessing from @haiderTranscriptomeAnalysisPhosphate2023, genes autoscaled i.e. blue indicates no/low expression and red indicates higher expression. IDs with functional annotations in supplementary table 1.")}

heat2 <- knitr::include_graphics("MASCARA_heatmap.png")
heat2
```



```{r ASCA-1, echo = F, out.width = '100%', fig.cap=c("Scores and loadings of the ASCA model of the combined effect (condition + condition:time interaction), model indicates samples and genes relative positions in the designed variance. *g_c* indicates growth condition, *time* indicates days after starvation induction.")}
knitr::include_graphics("rice_s_l.png")
```

\twocolumn



## Simulations

The problem in the real dataset is that the nutrient stress applied causes a major effect on many other genes besides our baits and targets . This widespread transcriptional regulation can mask the coexpression patterns of interest due to the large number of genes that are upregulated under the stress condition, making it more difficult to detect genes that are responding to a lesser extent, for example the SL pathway. 

The simulations are built upon the results of the ASCA analysis of the combined effect of growth condition and the interaction of growth condition (g_c) and time. As can be seen in Figure \@ref(fig:ASCA-1) there is clear separation between samples due to the experimental factors growth condition (g_c) and time. The variation between the replicates is only small. The green loadings of URP genes are strongly related to the experimental variation due to g_c. The simulated data is created by simulating experimental variation consisting of the main time effect $beta$ and the combined effect ($\alpha + \alpha\beta$), and the Ambient/Residual variation which exists of the structured ambient variance ($S$) and residual variation ($E$) representing measurement error, modeled with normally distributed random values $e_{ij} = \mathcal{N}(0,\sigma^2)$.

Each of the sources of variation except the residual variation is simulated as low dimensional variation created from 2 scores ($\mathbf{T}$) and loadings ($\mathbf{P}$). For the experimental variation, the scores matrices $\mathbf{T}_{\alpha + \alpha\beta}$ and $\mathbf{T}_{\beta}$ each consist of two orthogonal score vectors and their relative levels are indicated by the colour. The different colours in Figure \@ref(fig:simOverview) represent that the scores are orthogonal to each other. Each small block consists of the same score value for each of the replicates within that condition. For the Ambient variation, the scores $\mathbf{T}_{S}$ are different for each replicate plant. The values in $\mathbf{T}_{S}$ are obtained from a normal distribution with mean 0 and variance 1, i.e. $\mathbf{T}_{S_{ik}} \sim \mathcal{N}(0,1)$. The $\mathbf{T}$ matrices represent the simulated scores for their respective factors. For blues, reds, greys and golds we have 4 different shades representing 4 unique values per factor level (total 8 unique values where reds and golds are sign flipped blues and greys respectively). Similarly oranges and pinks represent a growth condition independent time profile with four unique values.

In the loading matrices $\mathbf{P}$, the different coloured blocks indicate different types of genes. The green block represents the bait genes of POI. The black genes represent “unknown” genes from POI or RP. Yellow and purple represent genes from URP that are affected by the experimental variation in different ways. The grey blocks represent very small background variation for those genes, while the white blocks represent that those genes are not affected by that source of background variation. 

In $\mathbf{P}_{\beta 1}^T$ the baits, spikes (simulated targets; term used throughout simulations) and other DE genes (all genes from POI, RP and URP) along with the remaining first half have similar positive values (represented by light grey) where the other 1000 have positive values in $\mathbf{P}_{\beta 2}^T$ (grey), these are created to emulate the reality of the real data in which many genes are slightly correlated with eachother through the course of development, as well as to account for some nonlinearities which are otherwise ignored by our model. The remaining elements of $\mathbf{P}_{\alpha + \alpha \beta}^T$ and $\mathbf{P}_{\beta}^T$ are populated with zeroes. $\mathbf{P}_S$ only has values for the baits (green) and spike (black) genes. The loading values for the baits and spikes are obtained as $p_{S_jk}^{baits,spikes} \sim \mathcal{N}(0.5,0.2)$, while the loadings for the other genes are 0. 

To finalise, the response values all have an intercept $\mathbf{1}\mu_{j}^T$. Similarly to the real data, the gene expression values for each experimental condition are simulated with three independent replicates per time-condition-combination. Each simulated data Y set thus consists of 24 samples and 2000 genes.

```{r simOverview, echo=FALSE, fig.cap="Coexpression simulation, simplified overview. Colours correspond to the same genes in the different loading vectors (*P*). Black; baits (known POI genes), green; spikes (unknown POI genes), yellow; DE URP genes, purple DE URP genes with a different profile. In the score vectors (T); Blues, reds, greys and golds represent experimental conditions, oranges and pinks; time. Each of the textures in the ambient/residual part represent a distinct normally distributed set of random values.", out.width = '100%'}
knitr::include_graphics("Sim_SL_diagram_simplified.png")
```



## Data simulation 1: Combined effect size and number of differential genes

The first simulation aims to determine how well the methods perform to find coexpressed genes in the presence of a dominant between-group variance structure and increasing numbers of differential URP genes (represented by the yellow block in Figure \@ref(fig:simOverview)) that only have high between-group variance but no within-group variance.

In this simulation we have a set of 4 baits, 12 spike genes and a variable number URP genes. The issue to address is the presence of many differential URPs; those that have strong between group correlation but no within group correlation with the POI. We incrementally increase the number of genes in the yellow block and decrease number of white genes with 0 loadings. As well as the number of DE URPs we also independently control the size of the experimental variance through the parameter *d* in Equation in \@ref(eq:nCER). This approach controls the size of the experimental variance as well as the number of genes responding while keeping a fixed amount of ambient or within group variation.

\begin{equation}
\begin{aligned}
\bm{Y} &= \bm{1\mu}^T + d(\bm{T}_{\alpha + \alpha\beta}\bm{P}_{\alpha + \alpha\beta}^T) + \bm{T}_{\beta}\bm{P}_{\beta}^T + \bm{T}_{S}\bm{P}_{S}^T + \bm{E} \\
\end{aligned}(\#eq:nCER)
\end{equation}


```{r, echo = FALSE}
X_funced_test2 <- Create_Core(nreps = 3, meta, irr_spikes = TRUE, struc_resid = FALSE,
                        a_sigma = c(1,1), b_sigma = c(1.5,1.5), e_sigma = c(1,0.3),
                        noise_sd = 0, EffectSize = c(X_a_ab = 1, time = 0, E = 0, mu = 1),
                        plot = TRUE)
```





## Data simulation 2: Replication

The second simulation focuses on the effect of a different number of replicates. We investigate a range of values for sizes of between experimental variance (*d*) and random noise variation (*l*) across random structures (which correspond to 20 repeated simulations of randomised values for all $\mathbf{T}$ matrices). 

\begin{equation}
\begin{aligned}
\bm{Y} &= \bm{1\mu}^T + d(\bm{T}_{\alpha + \alpha\beta}\bm{P}_{\alpha + \alpha\beta}^T) + \bm{T}_{\beta}\bm{P}_{\beta}^T + \bm{T}_{S}\bm{P}_{S}^T + l\bm{E} \\
\end{aligned}(\#eq:Test-2)
\end{equation}

On these 20 datasets, per condition, the replicate number $n_r$ was also varied: the number of replicates $n_r \in 3:15$ per experimental condition were sampled from a maximum $n_r$ of 15.

With this setup we test the feasibility range of MASCARA with respect to the ratio of 3 key variance parameters namely:
1. Within group correlation structure
2. Between group correlation structure
3. Random noise

Here we set a fixed size of within group correlation structure (\(\|\bm{T}_S\bm{P}_{S}^T\|_F = 0.025\)) as well as number of non-pathway DE genes to 30 (yellow bar size Figure \@ref(fig:simOverview)) across all iterations of this test. We vary the sizes of the other two variance parameters (*d* and *l*). Furthermore we also show the effect of replicate number and demonstrate that MASCARA (along with the other methods) can be applied to data with generic profiles, not limited to the specific structures that were used to demonstrate the differences in coexpression analysis with simulation 1. Here we create 20 datasets with random combined effect and within group correlation structures.




```{r, echo = FALSE}

X_funced_classic <- Create_Core(nreps = 3, meta, irr_spikes = FALSE, struc_resid = FALSE,
                        a_sigma = c(1,1), b_sigma = c(1.5,1.5), e_sigma = c(1,0.3),
                        noise_sd = 0, EffectSize = c(X_a_ab = 1, time = 0, E = 0, mu = 1),
                        plot = TRUE)



X_funced_test <- Create_Core(nreps = 3, meta, irr_spikes = FALSE, struc_resid = FALSE,
                        a_sigma = c(1,1), b_sigma = c(1.5,1.5), e_sigma = c(1,0.3),
                        noise_sd = 0.75, EffectSize = c(X_a_ab = 1, time = 0, E = 1, mu = 1),
                        plot = TRUE)



X <- X_funced_classic[[1]]
P <- X_funced_classic[[2]]
Pb <- X_funced_classic[[3]]
```

```{r, echo = F}
#create "ref" for feature spike information

ref <- cbind.data.frame(Feature = colnames(X), P, Pb)


cols <- colnames(ref[,-1])
ref$Effect <- do.call(paste, c(ref[cols], sep = "_"))

ref$Effect[which(ref$Effect == "0.5_0_0_0.1")] <- "Low PC1"
ref$Effect[which(ref$Effect == "1_0_0_0.1")] <- "Medium PC1"
ref$Effect[which(ref$Effect == "1.5_0_0_0.1")] <- "High PC1"
ref$Effect[which(ref$Effect == "0_0.5_0.1_0")] <- "PC2"

ref$Effect[grep("^0", ref$Effect)] <- "None"

ref$Effect <- factor(ref$Effect, levels = c("Low PC1", "Medium PC1", "High PC1", "PC2", "None"))


```




## Selection of genes of interest

### Ranked correlations

Pearson's correlation coefficient $r_{b\tilde{j}}$ is calculated between all bait genes (b = 1..B) and all other genes ($\tilde{j} = 1...\tilde{J}$). Ranks $\tilde{r}_{b\tilde{j}}$ are assigned for each $r_{b\tilde{j}}$ such that the highest correlation for each bait gene b receives the lowest rank. These ranks are averaged across all baits B (see supplementary equation \@ref(eq:rankcor)).


### ASCA+

ANOVA simultaneous component analysis (@smildeANOVAsimultaneousComponentAnalysis2005) involves splitting data into effect matrices which are defined by the experimental design structure, after which a PCA is applied to the effect matrices or combination thereof. In ASCA+ this variance partitioning is achieved through the generalised linear model as described in @thielASCAAPCAExtensions2017. ASCA+ addresses the issue of biased effects matrices in unbalanced designs. The following is a summary of the algorithm description provided in @thielASCAAPCAExtensions2017. 

The multivariate generalised linear model (GLM) can be expressed as:

\begin{equation}
\begin{aligned}
\mathbf{Y} = \mathbf{X} \mathbf{\Theta} + \mathbf{E}
\end{aligned}(\#eq:glm)
\end{equation}

where \(\mathbf{Y}\) is the response matrix of dimension \(I \times J\), \(\mathbf{X}\) is the model matrix of dimension \(I \times p\), containing the sumcoded indicator levels for each of the levels for each factor and their interactions,
 \(\mathbf{\Theta}\) is the parameter matrix of dimension \(p \times J\) and
 \(\mathbf{E}\) is the error matrix of dimension \(I \times J\).

Through Ordinary Least Squares (OLS) we can obtain the (unbiased) estimators of the model parameters:

\begin{equation}
\begin{aligned}
\hat{\mathbf{\Theta}} = (\mathbf{X}^\intercal \mathbf{X})^{-1} \mathbf{X}^\intercal \mathbf{Y}
\end{aligned}(\#eq:ols)
\end{equation}

The effect matrices for different terms of the model can be obtained as:

\begin{equation}
\begin{aligned}
\mathbf{M}_f = \mathbf{X}_f^* \hat{\mathbf{\Theta}}
\end{aligned}(\#eq:effects)
\end{equation}

where: $\mathbf{M}_f$ is the effect matrix corresponding to effect $f$, $\hat{\mathbf{\Theta}}$ is the matrix of estimated parameters obtained from OLS and $\mathbf{X}_f^*$ is a new model matrix obtained by keeping in $\mathbf{X}$ only the block $\mathbf{X}_f$ and replacing all other columns with zeros as per: 

\begin{equation}
\begin{aligned}
\mathbf{M}_f=\left[0|\mathbf{X}_f |0\right]\left[0|\mathbf{\hat{\Theta}}_f |0\right]^T = \mathbf{X}_f \mathbf{\hat{\Theta}}_f
\end{aligned}(\#eq:scim)
\end{equation}

The above is achieved through the sum coded indicator matrix as illustrated further in @thielASCAAPCAExtensions2017.

Furthermore, the matrix $\mathbf{E}$ is estimated as the residual matrix of the model:

\begin{equation}
\begin{aligned}
\hat{\mathbf{E}} = \mathbf{Y} - \mathbf{X} \hat{\mathbf{\Theta}}
\end{aligned}(\#eq:ascaresid)
\end{equation}

Throughout this text when referring to the calculation of ASCA/ASCA+ model on simulated or real data the following model is calculated:

\begin{equation}
\begin{aligned}
\mathbf{Y} = \mathbf{M}_{\alpha} + \mathbf{M}_{\beta} + \mathbf{M}_{\alpha\beta} + \mathbf{E}
\end{aligned}(\#eq:ascamodel)
\end{equation}

With genes selected from:

\begin{equation}
\begin{aligned}
\mathbf{\hat{Y}} =& \mathbf{M}_{\alpha} + \mathbf{M}_{\alpha\beta}
                 =& \mathbf{T}_{\alpha + \alpha\beta}\mathbf{P}_{\alpha + \alpha\beta}^T
\end{aligned}(\#eq:ascagenes)
\end{equation}

### PLS regression


Partial Least Squares (PLS2) is a multivariate regression technique used for modeling relationships between two sets of variables. Here we split our data matrix $\mathbf{Y}$ into sub-matrices; 

\begin{equation}
\begin{aligned}
\mathbf{Y} = \left[\mathbf{\tilde{Y}} | \mathbf{B}\right]
\end{aligned}(\#eq:plspart)
\end{equation}

The response matrix $\mathbf{B}$ contains only the baits (relating to the green bar in the loadings of Figure \@ref(fig:simOverview)) and the predictor matrix $\mathbf{\tilde{Y}}$ contains the rest of the data, this can then be expressed as:

\begin{equation}
\begin{aligned}
\mathbf{\tilde{Y}} = \mathbf{T}\mathbf{P}^T + \mathbf{E}_\tilde{Y} \\
\text{and} \\
\mathbf{B} = \mathbf{T}\mathbf{Q}^T + \mathbf{E}_B \\
\end{aligned}(\#eq:plsmodel)
\end{equation}


This model is estimated in our work using the SIMPLS algorithm (@dejongSIMPLSAlternativeApproach1993) as follows:

1. For the $1^{st}$ component:
   a. Compute the left singular vector $\mathbf{u}_1$ of $\mathbf{\tilde{Y}}_{k}^{T} \mathbf{B}_{k}$
   b. $\mathbf{t}_1 = \mathbf{\tilde{Y}}\mathbf{u}; \mathbf{T} = \left [\mathbf{t}_1\right]$
   c. $\mathbf{p}_1 = \frac{\mathbf{\tilde{Y}}^T\mathbf{t}^t}{\mathbf{t}^t\mathbf{t}}$
2. For the following components:
   a. Compute the left singular vector $\mathbf{u}_k$ of $(\mathbf{I} - \mathbf{P}(\mathbf{P}^T\mathbf{P})^{-1}\mathbf{P})\mathbf{\tilde{Y}}_{k}^{T} \mathbf{B}_{k}$
   b. $\mathbf{t}_k = \mathbf{\tilde{Y}}\mathbf{u}_k; \mathbf{T} = \left [\mathbf{T}|\mathbf{t}_k\right]$
   c. $\mathbf{p}_k = \frac{\mathbf{\tilde{Y}}^T\mathbf{t}_{k}^t}{\mathbf{t}_{k}^t\mathbf{t}_{k}}; \mathbf{P} = \left [\mathbf{P}|\mathbf{p}_k\right]$

Under the conditions of orthogonal scores; $\mathbf{t}_{k}^{T}\mathbf{t}_{k} = 0$ and normalised weights; $\mathbf{u}_{k}^T\mathbf{u}_{k{}} = 1$ . Loadings for B can be obtained with a least squares step $\mathbf{Q} = (\mathbf{T}^T\mathbf{T})^{-1}\mathbf{T}^T\mathbf{B}$.
   
In the following simulations and application the number of components calculated by PLS2 is set to 2 to create an interpretable model. 


### Variable importance in projection (VIP)

In this work genes are selected in both ASCA+ and PLS through VIP which is a way to measure the contributions of each variable to the underlying models. According to:

\begin{equation}
\begin{aligned}
\text{VIP}_{j} = \sqrt{\frac{ \sum_{k=1}^{K} H^2_{jk} \cdot \text{VE}_{k}}{\text{VE}_{total} \cdot K}}
\end{aligned}(\#eq:vip)
\end{equation}

Where k=1...K represents the number of components in the respective models, j indexes a gene,  $H$ is substituted for the loadings $\mathbf{P}_{\alpha + \alpha\beta}^T$ or weights $\mathbf{U}$ (for ASCA+ and PLS respectively) and VE is the variance explained, where $VE_{k}$ is the amount of variance explained by component k and $VE_{total}$ is the variance explained by the whole model. In ASCA+ we calculate the VIP scores in the latent space of \(\bm{Y}_{\alpha + \alpha\beta}\) as described in @thielASCAAPCAExtensions2017. In PLS we use the VE from the latent space of \(\bm{B}\) using the weights ($\mathbf{U}$) from the latent space of the predictor matrix \(\bm{Y}\).



### Multivariate ASCA residual analysis (MASCARA)


MASCARA combines the effect estimation with GLM (from ASCA+) with PLS2. The method entails estimating effect matrices with the GLM step of ASCA+ as described above to obtain the estimated residual matrix \(\hat{\mathbf{E}}\). The variance explained by all effect matrices of the experimental factors and interactions is removed. What remains in this \(\hat{\mathbf{E}}\) matrix is individual variance of each replicate that is assumed to contain not just random technical variance but some form of structured variance induced by ambient (uncontrolled) effects. The matrix \(\hat{\mathbf{E}}\) from equation \@ref(eq:ascaresid) is substituted as $\mathbf{Y}$ into PLS2  after being split into baits and remainder as per equation \@ref(eq:plspart).

The genes are ranked based on target projection (@kvalheimInterpretationPartialLeast2010) of the loadings $\mathbf{P}$ onto the mean vector of the bait loadings $\mathbf{Q}$ in 2 components: $\mathbf{\bar{q}} = \begin{bmatrix} \bar{q}_1 \\ \bar{q}_2 \end{bmatrix}$ where $\bar{q}_k$ is the mean of the $k^{th}$ component of the PLS2 model. The target projected loadings $\mathbf{P}_{TP}$ are calculated such that $\mathbf{P}_{TP} = \left( \frac{\mathbf{P} \cdot \mathbf{\bar{q}}}{\|\mathbf{\bar{q}}\|^2} \right)$. Higher values in the target projection equate to stronger positive associations with the center of the baits. Large negative values can also be interesting candidates for strong negative associations, although only positive associations are considered here. This approach allows a general direction in the PLS space to be defined by multiple baits and assumes that these baits are highly correlated with one another. 




## Performance evaluation; Log2 geometric mean rank

To evaluate performance we use $log_{2}$ geometric mean rank ($log_{2}(GMR)$; $\bar{\gamma}$), defined as: 

\begin{equation}
\begin{aligned}
\bar{\gamma} = log_{2}((\prod_{j_{spike}=1}^{J_{spike}}\gamma_{j_{spike}})^{1/J_{spike}})
\end{aligned}(\#eq:GMR)
\end{equation}

for $J_{spike}$ spikes. A lower $\bar{\gamma}$ indicates better performance.


# Results


```{r, echo = FALSE, include = F}
m <- meta
m[,1:2] <- lapply(meta[,1:2],factor)

res_ASCAplus_nb <- ASCA_decompose(d = m[,1:2], x = X_funced_test2[[1]],
                               f = "growth_condition + time + growth_condition:time")
```


```{r, echo = FALSE}


 minT <-  res_ASCAplus_nb$decomposition$growth_condition + res_ASCAplus_nb$decomposition$`growth_condition:time`
  PCD <- prcomp(minT)

  newdata <- res_ASCAplus_nb$decomposition$growth_condition + res_ASCAplus_nb$decomposition$`growth_condition:time` + res_ASCAplus_nb$residuals

  PCDE <- predict(PCD, newdata)
  # PCDE <- cbind(m[,1:2], PCDE)

```


```{r, echo = F}
a_c.PCD <- PCD
```

```{r, echo = F}

ve1 <- paste0(round(summary(a_c.PCD)$importance[2,1:2] * 100, digits = 2), "%")
l <- loadingplot(a_c.PCD$rotation, meta, baits, ve1, ref, aes(x = PC1,y = PC2, colour = Effect))
s <- scoreplot(PCDE, meta, ve1, aes(x= PC1, y = PC2, colour = growth_condition, shape = time))

qq <- qqplot(newdata, meta, aes(x=X_2000, y= X_1999, colour = growth_condition, shape = time))


ASCA_cands <- get_ASCA_cands(a_c.PCD,  distance_calc = T, baits = baits[9:12], ret_candN = 10)


CAND_TAB <- cbind.data.frame(rownames(ASCA_cands), ASCA_cands)
CAND_TAB <- CAND_TAB[1:10,]

colnames(CAND_TAB)[1] <- "Feature"


fill <- rep(c("grey95", "grey90"), nrow(CAND_TAB))
fill[which(CAND_TAB$Feature %in% baits)] <- "yellow"

theme1 <- ttheme_default(core = list(
  fg_params = list(fontface=c(rep("plain", nrow(CAND_TAB)))),
  bg_params = list(fill = fill)),
  base_size = 5, padding = unit(c(2, 2), "mm"))

candtab <- gridExtra::tableGrob(CAND_TAB, rows = NULL, theme = theme1)

```




```{r,echo = F}

Noise_Tests <- readRDS("Noise_Sim_Coexp_24_01_22.RDS")


names(Noise_Tests) <- c("ASCA", "PLS", "Correlations", "MASCARA")

Noise_Tests <- Noise_Tests[c("ASCA", "PLS", "Correlations","MASCARA")]
Noise_Tests <- lapply(Noise_Tests, narm, keep_col1 = T)



y <- rep((c(0:10)/50))
x <-  c(0:10) * 5  


x <- rep(x,each = length(y))
y <- rep(y, length(unique(x)))
z <- x*y

main_lev  <-  z

ERs <- x
```

```{r}
names <- paste(ERs,main_lev, sep = "_")

i <- NULL
for(i in 1:length(Noise_Tests)){
  colnames(Noise_Tests[[i]]) <- names
}

i <- NULL
RES <- data.frame(matrix())
for(i in 1:1){
  res <- Noise_Tests[[i]][16,]
  RES <- cbind.data.frame(RES,t(res))
}


for(i in 2:4){
  res <- Noise_Tests[[i]][12,]
  RES <- cbind.data.frame(RES,t(res))
}


RES <- RES[,-1]
colnames(RES) <- names(Noise_Tests)
```

```{r, echo = F}
RES <- cbind.data.frame(rownames(RES), RES)
colnames(RES)[1] <- "Cond"

mRES <- melt(RES)

colnames(mRES)[c(2,3)] <- c("Method","F1")

mRES$Noise <- rep(ERs, 4)
mRES$Main <- rep(main_lev, 4)
```

```{r, echo=FALSE}

mRES$F1 <- as.numeric(mRES$F1)

colnames(mRES)[3] <- "GMR"
mRES$GMR <- log2(mRES$GMR)
# colnames(mRES)[5] <- "GMR"

mRES$Size_num <- rep(y, 4)
```

```{r}
mRES <- mRES[-which(mRES$Main == 0),]
mRES <- mRES[-which(mRES$Size_num >= 0.15),]
mRES <- mRES[-which(mRES$Noise >=35),]

max <- max(mRES$GMR)
min <- min(mRES$GMR)

```


```{r, echo=FALSE}
i <- NULL
methods <- unique(mRES$Method)
plots <- list()
for(i in 1:length(methods))
  plots[[i]] <- ggplot(mRES[which(mRES$Method == methods[i]),], aes(x = Noise, y = Size_num))+ 
    geom_tile( aes(fill = GMR)) + #position = "jitter",

    scale_fill_continuous(type = "viridis", limits = c(min,max))+

  ggtitle(methods[i]) +
  ylab("Effect Size") + 
  xlab("Num. DEs") +
  theme_bw() +
  labs(fill = "log2(GMR)") +
  theme(plot.title = element_text(size=8)) 
```


## Simulation 1: Combined effect size and number of differential genes

For this simulation we have some experimental variance for the combined effect and time ($\bm{T}_{\alpha + \alpha\beta}\bm{P}_{\alpha + \alpha\beta}^T$ and $\bm{T}_{\beta}\bm{P}_{\beta}^T$ respectively) a fixed amount of random noise \(\bm{E}\) and a fixed amount of structured ambient/residual variance $\bm{T}_S\bm{P}_{S}^T$, within which our 4 baits and 12 spikes share a correlation structure. This reflects the situation expected from the real data example - drastic effect caused by nutrient deficiency, which also activates the SL pathway. The POI genes are expected to share some variance that is independent to the experiment, the 4 baits and 12 spikes load on to the structured part of the noise $\bm{T}_S\bm{P}_{S}^T$.

```{r tc, echo = F, fig.cap= "Results of simulation 1 for all 4 methods. Log2 geometric mean rank (log2(GMR)) as a function of the number of differentially expressed URP genes (x-axis) and combined effect size (y axis); ($CE = \\|\\mathbf{T}_{\\alpha + \\alpha\\beta}\\mathbf{P}_{\\alpha + \\alpha\\beta}^T\\|_F$), lower log2(GMR); dark blue, indicates better performance. ASCA model calculated per equation \\@ref(eq:ascamodel), PLS model per equation \\@ref(eq:plsmodel)."}
wrap_plots(plots) + plot_layout(guides = "collect")

```

We can see in Figure \@ref(fig:tc) that MASCARA was neither affected by the presence of an increasing number of non-pathway DE genes nor the size of this effect. Correlations, ASCA and PLS, however, all showed the expected breakdown in performance due to the injection of more DE URP genes. This was the expected result as the experimental between group variance is removed with MASCARA.

## Simulation 2: Replication


```{r, echo = F}
#30 random initial scores, similar noise 
#parameters, 3-30 replicates per condition. 

Rep_Tests <- readRDS("Noise_Sim_24_01_22_Replicate_Tests.RDS")  

names(Rep_Tests) <- c("ASCA", "PLS","Correlations","MASCARA")


# names(Noise_Tests) <- ms$Method
Rep_Tests <- lapply(Rep_Tests, narm, keep_col1 = T)

names <- c()
l <- 1

y <- rep(c(0.0004,0.002, 0.01),3)      
x <- rep(25,9)
nse <- rep(c(0.1,0.2,0.3), each = 3)
DS <- c(1:9)

main_lev <- x*y

ERs <- DS

a <- NULL
for(a in 1: length(ERs)){
  i <- NULL
for(i in 1:20){
  j <- NULL
  for(j in 3:15){
    name <- paste0("Dataset_",i,"_Rep_",j,"_nCERS_",ERs[a])
        name <- paste0("Dataset_",i,"_Rep_",j,"_nCERS_",ERs[a])

    names <- c(names,name)
  }
}

}
```

```{r}
i <- NULL
for(i in 1:length(Rep_Tests)){
  colnames(Rep_Tests[[i]]) <- names
}

i <- NULL
RES <- data.frame(matrix())
for(i in 1){
  res <- Rep_Tests[[i]][16,]
  RES <- cbind.data.frame(RES,t(res))
}

for(i in 2:4){
  res <- Rep_Tests[[i]][12,]
  RES <- cbind.data.frame(RES,t(res))
}


RES <- RES[,-1]
colnames(RES) <- names(Rep_Tests)
```


```{r, echo = F}
RES <- cbind.data.frame("Replicate_Number" = gsub(".*Rep_","",rownames(RES)), RES)
RES <- cbind.data.frame("nCERs" = gsub(".*ERS_","",RES$Replicate_Number), RES)
RES$Replicate_Number <- gsub("_nCE.*","",RES$Replicate_Number)

mRES <- melt(RES)
colnames(mRES)[3:4] <- c("Method","F1_Score")
```

```{r, echo = F}
mRES$Replicate_Number <- as.numeric(mRES$Replicate_Number)#, c(3:30))
```

```{r}

orders <- c(7,8,9,4,5,6,1,2,3)

max <- max(log2(mRES$F1_Score) + 1)
i <- NULL
l <- 1
One_Balance <- list()
for(i in orders){
  
  One_Balance[[i]] <- ggplot(mRES[which(mRES$nCERs == orders[i]),], aes(x = Replicate_Number, y = log2(F1_Score), colour = Method, shape = Method, fill = Method)) +
  scale_color_viridis(discrete = T)+
    stat_summary() +
    ylim(0,max ) +
  labs(subtitle = paste0("CE = ", main_lev[l], " E = ", nse[l]))+
  theme_dark() +
      theme(axis.title = element_blank()) 

  l <- l + 1
  
}
```


```{r repres, echo = F, fig.cap= c("Simulation 2 results. Replications and variance type feasibility ranges. X axes; replicate number, y axes log2 transformed geometric mean rank. Each facet is created with set parameters for combined effect size ($CE = \\|\\mathbf{T}_{\\alpha + \\alpha\\beta}\\mathbf{P}_{\\alpha + \\alpha\\beta}^T\\|_F$) and random gaussian noise size ($E = \\|\\mathbf{E}\\|_F$). Dots are median performance across 20 random structures.  ASCA model calculated per equation \\@ref(eq:ascamodel), PLS model per equation \\@ref(eq:plsmodel).")}



ps <- patchwork::patchworkGrob(wrap_plots(One_Balance) + plot_layout(guides = "collect"))  #, heights = unit(c(5), c("cm")), widths = c(5))


test_patch <- (One_Balance[[1]] + One_Balance[[2]] + One_Balance[[3]]  + ylab(NULL))
              # (One_Balance[[4]] + One_Balance[[5]] + One_Balance[[6]]  + ylab(NULL))/
              # (One_Balance[[7]] + One_Balance[[8]] + One_Balance[[9]]  + ylab(NULL)) # + plot_layout(guides = "collect")

# One_Balance[[1]] + One_Balance[[2]]/
#   One_Balance[[3]] + plot_layout(guides = "collect")

# ps1 <- grid.arrange(ps, left = "log2(GMR)", bottom = "Replicate Number                     ")

a <- knitr::include_graphics("replication_res.png")
a


```


It was expected that all geometric mean ranks converge towards a minimum with increasing numbers of replicates, see \@ref(fig:repres). Perfect detection of 12 spikes in top 12 candidates is achieved with a log2 geometric mean rank of 2.4, MASCARA was able to achieve this, however, the other methods were perturbed by the presence of the 30 differential URP genes. With more replicates MASCARA always outperforms competitors. With higher values of *d* (larger combined effect size) (CE) MASCARA outperforms the other methods but its performance is affected by amount of random noise (E) size indicated by *l*. 

In simulation 2 we fixed the number of differential URP genes to 30, however this is less than 2% of the total number of genes in each dataset. In the real data example more than 10% of of the total number of genes are differentially expressed. As shown in simulation 1 (Figure \@ref(fig:tc)) higher numbers of DE URP genes results in higher log2 geometric mean rank (log2(GMR)) of the spikes for correlations, ASCA and PLS.  MASCARA is designed specifically to mitigate the effect of large numbers of DE URP genes. Here we show that this is achieved.


# Real Data Applications

It is apparent that MASCARA has a particular use case for coexpression analysis in data where there is a lot of experimentally induced between-group variance across many genes as well as some within-group correlation structure shared between POI genes that is caused by independent non-controlled ambient factors.

Here we illustrate an application of MASCARA to the dataset from @haiderTranscriptomeAnalysisPhosphate2023. For this we take 4 core strigolactone genes (Os11t0587000, Os04t0550600, Os01t0746400 and Os01t0700900 of the 9 used for illustrations in Figures \@ref(fig:Dataset1-Overview) and \@ref(fig:ASCA-1)) as baits and investigate their relationship with top candidate genes. 


```{r real data import}

X <- readRDS("Data_Haider/Rice_Counts4ASCA.RDS")
meta <- readRDS("Data_Haider/Rice_Meta4ASCA.RDS")
# colnames(meta)[c(6,7,11)] <- c("gc","time","growth_condition")

X <- t(assay(X))

colnames(meta)[3] <- "time"

baits <- paste0(c("Os11t0587000","Os04t0550600","Os01t0746400","Os01t0700900"),"-01") 
#D27 CCD7 CCD8 CYP711A2
baits2 <- c("Os01t0700300-00", "Os02t0817900-01")  # identified methyltransferases



meta$time <- as.character(meta$time)

meta$time[which(meta$time == "8")] <- "1"
meta$time[which(meta$time == "10")] <- "3"
meta$time[which(meta$time == "14")] <- "7"
meta$time[which(meta$time == "15")] <- "8"



ref <- cbind.data.frame(Feature = colnames(X), feature = colnames(X), Baits = colnames(X))

REF <- fread("Rice_Annotation/IRGSP-1.0_representative_annotation_2022-09-01.tsv",sep = "\t", header = T)

ref <- ref[which(ref$Feature %in% REF$Transcript_ID),]
ref <- merge(ref,REF[,c("Transcript_ID","Description")], by.x = "Feature", by.y = "Transcript_ID")

X <- X[,which(colnames(X) %in% ref$Feature)]
ref <- ref[match(colnames(X),ref$Feature),]

SL_ref <- ref[grep("trigolact",ref$Description),]

SL_ref <- ref[grep("trigolact",ref$Description),]
SL_ref <- SL_ref[-which(SL_ref$Feature %in% c("Os01t0701400-01","Os03t0203200-01","Os01t0763200-01","Os04t0668900-01","Os06t0154200-01","Os11t0104300-01","Os08t0250900-01")),]


PSI_ref <-read.table("Rice_Annotation/PSI_genes.txt", sep = "\t", header = T)


ref$Baits[-which(ref$Baits %in% c(baits,baits2,SL_ref$Baits))] <- "non_pathway"
ref$Baits[which(ref$Baits %in% baits)] <- "bait"

ref$Baits[which(ref$Baits %in% c(SL_ref$Baits[-which(SL_ref$Baits %in% baits)],baits2))] <- "bait"



ref$Baits[which(ref$Baits != "bait")] <- "Other"
ref$Baits[which(ref$Baits == "bait")] <- "Pathway"

```

```{r}
meta <- meta[order(meta$time),]
meta <- meta[order(meta$growth_condition),]
```


```{r}
X <- X[match(meta$ID, rownames(X)),]
```



```{r, echo = FALSE, include = F}
m <- meta
m[,c("growth_condition","time")] <- lapply(m[,c("growth_condition","time")],factor)


res_ASCAplus_nb <- ASCA_decompose(d = m[,c("growth_condition","time")], x = X,
                               f = "growth_condition + time + growth_condition:time")
```


```{r, echo = FALSE}

 minT <-  res_ASCAplus_nb$decomposition$growth_condition + res_ASCAplus_nb$decomposition$`growth_condition:time`
  PCD <- prcomp(minT)
  
  newdata <- res_ASCAplus_nb$decomposition$growth_condition + res_ASCAplus_nb$decomposition$`growth_condition:time` + res_ASCAplus_nb$residuals
  

  PCDE <- predict(PCD, newdata)
  
      F_norms <- c(do.call(c,lapply(res_ASCAplus_nb$decomposition,norm, type = "F")), 
                 residual = norm(res_ASCAplus_nb$residuals, type = "F"))


```  


```{r, echo = F, include = FALSE}
a_c.PCD <- PCD
```



```{r, echo = F, inlcude = F}
ve1 <- paste0(round(summary(a_c.PCD)$importance[2,1:2] * 100, digits = 2), "%")

loadingplot <- function(df, meta, baits, ve, ref, ...){
  #df is PCD$rotation

  #rematch REF, ref, df
  df <- as.data.frame(df)
  df <- cbind.data.frame(ref,df)

  ggplot(df, ...) +

    xlab(paste0("PC1 ",ve[1])) +
    ylab(paste0("PC2 ",ve[2])) +

    geom_point(data = df[which(df$Baits == "Other"),], alpha = 0.1) +
    geom_point(data = df[which(df$Baits == "Pathway"),], alpha = 1) +
    scale_x_continuous(guide = guide_axis(check.overlap = TRUE)) +
    guides(shape = guide_legend(override.aes = list(size = 0.5))) +
    ggtitle("Loadings") +
    theme_bw()+
        scale_colour_discrete(name=NULL)

}



l <- loadingplot(a_c.PCD$rotation, meta, c(baits,baits2), ve = ve1, ref = ref, aes(x = PC1,y = PC2, colour = Baits, label = Description))

meta2 <- meta
colnames(meta2)[2] <- "g_c"

scoreplot <- function(df, meta, ve, ...){
  
  #df <- as.data.frame(df)
  df <- cbind.data.frame(meta,df)
  df$time <- factor(df$time, levels = c(1:4))
  df$g_c <- factor(df$g_c)
  
  
  ggplot(df, ...)+
    geom_point() +
    xlab(paste0("PC1 ",ve[1])) +
    ylab(paste0("PC2 ",ve[2])) + 
    theme_bw()
  
}
s <- scoreplot(PCDE, meta2, ve1, aes(x= PC1, y = PC2, colour = g_c, shape = time)) + ggtitle("Scores")

#+ guide_area()# + plot_layout(design = design)
qq <- qqplot(newdata, meta, aes(x=X_2000, y= X_1999, colour = growth_condition, shape = time))


ASCA_cands <- get_ASCA_cands(a_c.PCD)
colnames(ASCA_cands) <- c("VIP", "PC1","PC2")
#kable(head(ASCA_cands,10))

CAND_TAB <- round(ASCA_cands[1:10,], 4)
CAND_TAB <- cbind.data.frame(rownames(CAND_TAB), CAND_TAB)
colnames(CAND_TAB)[1] <- "Feature"


fill <- rep(c("grey95", "grey90"), nrow(CAND_TAB))
fill[which(CAND_TAB$Feature %in% baits)] <- "yellow"

theme1 <- ttheme_default(core = list(
  fg_params = list(fontface=c(rep("plain", nrow(CAND_TAB)))),
  bg_params = list(fill = fill)),
  base_size = 5, padding = unit(c(2, 2), "mm"))

candtab <- gridExtra::tableGrob(CAND_TAB, rows = NULL, theme = theme1)


```


```{r, include = F}
source("DATA_SIM_FUNCS.R")
source("MASCARA_FUNCS.R")

pcd <- prcomp(res_ASCAplus_nb$residuals)
residual_cands <- get_ASCA_cands(pcd)

```


```{r, inlcude = FALSE}

minT <-  res_ASCAplus_nb$decomposition$time
tcd <- prcomp(minT)

newdata <- res_ASCAplus_nb$decomposition$time + res_ASCAplus_nb$residuals
PCDE <- predict(PCD, newdata)

tcd <- prcomp(res_ASCAplus_nb$decomposition$time + res_ASCAplus_nb$residuals)
```


```{r, include = F}

pathway <- ref[which(ref$Baits == "Pathway"),1]

p_n_b <- pathway[-which(pathway %in% baits)]

psi_ref <- PSI_ref[which(PSI_ref[,1] %in% colnames(res_ASCAplus_nb$residuals)),]

image(cor(res_ASCAplus_nb$residuals[,c(pathway,psi_ref[,1])]))
```

```{r}
get_ASCA_cands2 <- function(PCD, meta, distance_calc= FALSE, baits = NULL, spikes = NULL, ret_candN = nrow(PCD$rotation)){
  #############
  
  if(distance_calc== TRUE){
    
    cands <- ranked_dist(baits,PCD)
    
  }else{
    absload <- abs(data.matrix(PCD$rotation[,1:2])) %*% diag(summary(PCD)$importance[2,1:2])
    combscore <- rowSums(absload[,1:2])
    
    
    orderedload <- cbind(combscore, PCD$rotation[,1:2])
    cands <- as.data.frame(orderedload[order(orderedload[,1], decreasing = T),])
    colnames(cands) <- c("VIP", "PC1","PC2")
    
    cands <- round(cands[1:ret_candN,], 4)
    
    
  }
  
  return(cands)
  
  
}


ASCA_cands2 <- get_ASCA_cands2(a_c.PCD)
ASCA_cands2 <- ASCA_cands2[which(ASCA_cands2[,2] < 0),]
ASCA_cands2 <- ASCA_cands2[order(ASCA_cands2[,2]),]
```

In the real data from @haiderTranscriptomeAnalysisPhosphate2023 some plants were subjected to massive stress with the phosphate limitation. This is, therefore, reflected by large differences in the transcriptome compared to those with a normal supply of P. This limitation affected many more genes than those directly involved in SL biosynthesis. Furthermore, there appears to be a stronger relationship amongst the SL genes in the ambient variation compared to their correlations with other DE URP genes, as displayed in Figure \@ref(fig:residualdists) where the blue distribution indicates correlations between residuals of the 9 POI transcripts from Figures \@ref(fig:Dataset1-Overview) and \@ref(fig:ASCA-1) and the red indicates correlations between residuals of these 9 and top DE URP genes.

```{r residualdists, fig.cap=c("Distributions of Fisher transformed Pearson correlations (supplementary equation \\@ref(eq:Fisher)) in residuals from the ASCA model on the data from @haiderTranscriptomeAnalysisPhosphate2023. Blue indicates correlations between SL pathway genes, red indicates correlations between SL pathway genes and top 10% DE URP genes (upregulated in P- over P+).")}


cor_val <- function(x){
  cor_res <- cor(x[])
  cor_res <- 0.5*log((1+cor_res)/(1-cor_res))
  return(cor_res)
}

test <- cor_val(res_ASCAplus_nb$residuals[,pathway])  #res_ASCAplus_nb$residuals

#define top DE ID vector, with no SL genes
ASCA_cands2 <- ASCA_cands2[-which(rownames(ASCA_cands2) %in% pathway),]
non_pathway <- rownames(ASCA_cands2)[1:1253]

test2 <- cor_val(res_ASCAplus_nb$residuals[,c(pathway,non_pathway)])
test2[upper.tri(test2, diag = T)] <- NA

mt <- melt(test2, na.rm = T)
mt$group <- as.character(mt$Var1)

mt$group[which(mt$Var1 %in% pathway & mt$Var2 %in% pathway)] <- "SL-SL"


mt$group[which(mt$Var1 %in% non_pathway & mt$Var2 %in% pathway)] <- "SL-Other"

mt <- mt[which(mt$group %in% c("SL-SL","SL-Other")),]
colnames(mt)[3] <- "Correlation"
dens <- ggplot(mt, aes(Correlation, colour = group)) + geom_density() + theme_bw()
dens
```

```{r}
all <- cbind.data.frame(meta[,c("growth_condition","time")], X)
residuals <- cbind.data.frame(meta[,c("growth_condition","time")], res_ASCAplus_nb$residuals)


cutoff <- round(quantile(c(1:nrow(ASCA_cands)),0.1))
res_filt <- residuals[,c(1:2,which(colnames(residuals) %in% rownames(ASCA_cands)[1:cutoff]))]

resids <- res_filt[,-c(1:2)]


```


```{r}
coexp_cands <- ranked_coexp(baits,X[,which(colnames(X) %in% colnames(resids))])

sPLS_cands <-  MASCARA(data.matrix(resids), baits)[[1]]             #MASCARA

```

Some example top coexpression candidate genes are shown in Figure \@ref(fig:realcandidates). The problem of dominant between group variation is again exemplified here. Several of the top candidates detected by correlations (ASCA and PLS, results not shown) show no indication of within group correlations. Candidates selected with MASCARA, on the other hand, consistently show within group correlations with the baits. Furthermore, the strigolactone pathway, which is still under active investigation, has several uncharacterised biosynthetic steps. These are thought to be carried out by cytochrome p450s. The top candidates from MASCARA contain at least three (putative) cytochrome p450 genes that have not yet been biologically investigated in SL biosynthesis, as well as, a methyltransferase and several putative carotenoid synthesis genes. MASCARA also detected genes linked to Gibberellins (GA) preferentially to general phosphate starvation genes. The GA pathway has been linked to the strigolactones (@itoRegulationStrigolactoneBiosynthesis2017, @marzecStrigolactonesGibberellinsNew2017). The interaction between these two pathways has been characterised recently under nitrogen limitation by @sunStrigolactoneGibberellinSignaling2023.


```{r realcandidates, fig.cap="Example candidates from A-C ranked correlations and D-F MASCARA. X axes; transformed expression level of one of the bait genes (CCD8), y axes; expression levels of three example coexpression candidates for each method (see @haiderTranscriptomeAnalysisPhosphate2023 for preprocessing details)."}


qqplots_spls <- list()
qqplots_coexp <- list()


i <- NULL
for(i in 1:20){
  qqplots_spls[[i]] <- qqplot(cbind.data.frame("Candidate" = X[,which(colnames(X) %in% rownames(sPLS_cands)[i])],
                        "Bait" = X[,which(colnames(X) %in% baits[1])]),meta, 
       aes(x = Bait, y = Candidate, colour = growth_condition, shape = time)) + ylab(rownames(sPLS_cands)[i])
  
  qqplots_coexp[[i]] <- qqplot(cbind.data.frame("Candidate" = X[,which(colnames(X) %in% rownames(coexp_cands)[i])],
                        "Bait" = X[,which(colnames(X) %in% baits[1])]),meta, 
       aes(x = Bait, y = Candidate, colour = growth_condition, shape = time)) + ylab(rownames(coexp_cands)[i])
  

}

plot1 <- wrap_plots(qqplots_coexp[c(6,8,10)]) + plot_annotation(title = "Correlations") #+ theme(aspect.ratio = 1)
plot2 <- wrap_plots(qqplots_spls[c(2:4)]) + plot_annotation(title = "MASCARA") #+ theme(aspect.ratio = 1)

# wrap_plots(qqplots_spls) + plot_layout(guides = "collect",tag_level = 'new')

PLOT <- plot1/plot2 + plot_layout(guides = "collect",tag_level = 'new') + plot_annotation(tag_levels = c('A','1'))
# ggsave("within_between_example.png", PLOT)

a <- knitr::include_graphics("within_between_example.png")
a

```



# Discussion and conclusions

In this article we introduced multivariate ASCA residual analysis (MASCARA) as a method for coexpression analysis in data containing a dominant variance structure from a known (experimental) source. MASCARA estimates effects through the GLM with a design matrix to remove the variance between conditions, then the residual matrix can be decomposed through PLS2, with feature ranking through target projections. This framework enables the investigation of multivariate relationships between a set of bait genes and all other genes in the dataset. MASCARA thrives on the fact that within the typical experimental setup small systematic variance exists between replicates due to variations in ambient factors that affect the plant, and therefore the variance structures in the resulting data. 

Through simulation studies we showed the conditions under which MASCARA is suitable for coexpression analysis and compared it to a selection of other coexpression methods (ASCA+, PLS2 and correlations). These methods were applied to data from @haiderTranscriptomeAnalysisPhosphate2023 exploring the strigolactone pathway and simulated data based on the structure of the Haider data. In a coexpression context, within certain assumed parameters of variance structure (dominant between-group, existing within-group), MASCARA outperformed competitors. Ranked correlations, ASCA (@smildeANOVAsimultaneousComponentAnalysis2005, @thielASCAAPCAExtensions2017) and PLS (@woldCollinearityProblemLinear1984) are all affected by dominant experimental between-group variance, which is a common occurrence in experimental data, exemplified here by the dataset from @haiderTranscriptomeAnalysisPhosphate2023 but discussed elsewhere (@farahbodUntanglingEffectsCellular2020, @zhaoWeightedGeneCoexpression2010, @chowdhuryDifferentialCoExpressionAnalysis2020). 

The feature selection stage of MASCARA uses an average vector constructed from the loadings of the baits onto which the loadings of other genes are projected. This approach is similar to target projection in @kvalheimInterpretationPartialLeast2010 although we construct the target vector from averaging the loadings in a PLS2 model as opposed to already having it defined with the univariate response in PLS1. There are many established methods for feature selection in PLS which include Variable Importance in Projection (VIP) and Selectivity Ratio (@rajalahtiBiomarkerDiscoveryMass2009), however these methods focus on the importance of variables in the construction of the model rather than a directional association with the response block as with the $\mathbf{\bar{q}}$ target projection stage. With this averaged target projection approach, as an extension of Kvalheim's target projection in PLS1 models @kvalheimInterpretationPartialLeast2010, we can use the information in a set of baits to define a direction in the latent space which can then be used as an axis to determine the relatedness of other genes. This assumes moderate to high correlation in the residuals of the baits, which is a realistic assumption in coexpression analysis although should be verified in the selection of baits.

Our analysis framework does not consider different correlation structures within the residual variance, this could be an issue especially in the cases similar to @caldanaHighdensityKineticAnalysis2011 where different combinations of experimental factors show different within-group correlation structures. This type of relationship can be seen in Figure \@ref(fig:realcandidates) where the P- experiments show high positive correlation between the genes of the same pathway while the P+ experiments show a negative correlation.  With MASCARA these will not be preferentially detected, as the focus is on detecting positively associating features. Ideally there would be enough samples to calculate robust correlations per group, to account for possible rewiring under different conditions, but in our case we focus on experiments where there are generally not enough replicates to do this. Experiments with higher replication number are always desirable from the point of view of data analysis. However, this is not always feasible due to time and space constraints. We tested the effects of replication number and found that MASCARA can outperform its competitors with lower replication, especially in data containing many differential genes between experimental conditions. This advantage holds as long as there is a realistic amount of structured variance caused by undocumented ambient factors. 

In coexpression analysis, there is no need for class balance, it is in fact better to have more data points in the class where the pathway is induced (P- in the example dataset). When the POI is only active in the case condition then the control samples are mostly redundant. With more samples in the condition of interest the reliability of the coexpression analysis will improve. The MASCARA approach indicates that the typical experimental design used for DE is not optimal for coexpression studies. The fact that the residuals need to be isolated to find within group variance confirms the notion that coexpression analysis warrants different experiments than those used for DE studies. If quantification of differential expression is also needed, for example to confirm the pathway under study is affected by the treatment, but the main focus of research is coexpression, then it is an option to have just a few samples in a control condition to confirm the experimental treatment has caused the desired effect. This was not tested explicitly here, however if pathway genes are not active in a given condition then this set of samples does not provide any useful coexpression information.

This work has outlined and tested a basic use of MASCARA where the relationship between baits and unknown pathway genes is predefined to be positive. The method is not limited to the calculation of positive associations, however performance in detecting negative correlations (indicative of inhibitory or negative feedback processes) or more complex relationships has not been tested within the current simulations. Our approach was based on the structure of the study by Haider with RNAseq measurements of rice plants, however the method is applicable across other organisms and omics types. This holds under the assumption that the set of baits have a multivariate relationship between themselves and multiple other (unknown) genes. These genes are also related to the baits, as in our partially characterised strigolactone pathway example. In untargeted metabolomics datasets under similar experimental conditions these assumptions are also likely to be met.

Taken together our results indicate that the lack of ability to discern different types of variance in a dataset can compromise the detection of true coexpression patterns. MASCARA accounts for the different types of (experimental and ambient) variance and enables finer scale detection of within group variance structure. Code and data for this project are available at https://github.com/BiosystemsDataAnalysis/MASCARA.


# Acknowledgements

We acknowledge funding by the Dutch Research Council (NWO/OCW) for the MiCRop Consortium program, Harnessing the second genome of plants (Grant number 024.004.014; to HB, LD, AKS, JAW), the Dutch Research Council (NWO-TTW) Holland Innovative Potato (grant 16873; to HB, LD, FW) and the Data Science Centre of the University of Amsterdam (to FW). FW would like to thank Frans van der Kloet, Fentaw Abegaz, Roel van der Ploeg for statistical discussions and Imran Haider for consultation on the strigolactone pathway.

# References

<div id="refs"></div>


# Supplementary

Target projection in PLS2 models has not been described in the literature, we therefore tested our approach against the most common methods for feature selection in PLS namely variable importance in projection (VIP) and selectivity ratio (SR). Here we have similar but reduced simulation set up to the replicate test section; 3 levels of unstructured noise; matrix F-norm sizes (as indicated in the panels). In each of the 3 tests the $\mathbf{T}_S$ is randomised 30 times resulting in different correlation structures between baits and spikes. Target projection using $\mathbf{\bar{q}}$ significantly outperforms the conventional approaches.


```{r fig.cap="Feature selection simulation, selectivity ratio; SR, target projection; TP and variable importance in projection (VIP) compareed at 3 levels of noise, indicated in facet titles."}
Rep_Tests <- readRDS("Noise_Sim_23_07_30_FS_Tests.RDS")  #_3  Noise_Sim_23_06_23_Replicate_Tests.RDS
names(Rep_Tests) <- c("TP","SR","VIP","SVD1")

RES <- cbind.data.frame(t(Rep_Tests[[1]][1,]), t(Rep_Tests[[2]][1,]), t(Rep_Tests[[3]][1,]), t(Rep_Tests[[4]][1,]))

RES <- cbind.data.frame("E" = c(rep(c(5,10,15), each = 30)), RES)
colnames(RES) <- c("E", names(Rep_Tests))



mRES <- pivot_longer(RES,c("TP","SR","VIP","SVD1"))
colnames(mRES) <- c("E","Method","RP")

mRES <- mRES[-which(mRES$Method == "SVD1"),]

ggplot(mRES, aes(x = Method, y = RP)) +
  geom_boxplot() +
  facet_grid( ~E)

```

## Ranked correlations
Ranked correlations are calculated as:

\begin{equation}
\begin{aligned}
Rank_{\tilde{J}} = \frac{\sum_{b=1}^{B}\tilde{r}_{b\tilde{j}}}{B}  
\end{aligned}(\#eq:rankcor)
\end{equation}

Where *B* is the number of baits and $rank_{b\tilde{j}}$ is the ranked Pearson correlation coefficient between gene j and bait b in the context of $\tilde{J}$ non-bait genes.

## Fisher transformed Pearson correlation coefficient
To calculate Fisher transformed Pearson correlations (z) with Pearson's r:

\begin{equation}
\begin{aligned}
z = \frac{1}{2}ln(\frac{1 + r}{1-r})
\end{aligned}(\#eq:Fisher)
\end{equation}

